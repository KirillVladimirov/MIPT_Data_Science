{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18b94198-dabb-48e3-8678-9afab2cba3ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skitarii/PycharmProjects/mipt-masters/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchmetrics.functional import accuracy as tm_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb7117c-3ab4-41e4-a9ed-3bfcb000f87c",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cbbce36-a40e-4f05-8d94-71cbf16f3109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Автоматическое определение колонок\n",
    "_PIXEL_RE = re.compile(r\"pixel(\\d+)\", flags=re.IGNORECASE)\n",
    "\n",
    "def _detect_columns(df: pd.DataFrame) -> Tuple[str, str, Sequence[str]]:\n",
    "    \"\"\"\n",
    "    Находит названия ключевых столбцов в CSV-фиде.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Загруженный датафрейм (train или test).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    label_col : str\n",
    "        Имя столбца с метками классов (0–9). Может быть None в тесте.\n",
    "    id_col : str\n",
    "        Имя столбца с уникальным идентификатором строки. Может быть None.\n",
    "    pixel_cols : list[str]\n",
    "        Список из 784 имён столбцов вида pixel0 … pixel783 в правильном порядке.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        Если найдено не ровно 784 столбца-пикселя.\n",
    "    \"\"\"\n",
    "    # Приводим имена к lower-case, чтобы быть нечувствительными к регистру\n",
    "    lower = {c.lower(): c for c in df.columns}\n",
    "    label_col = lower.get(\"label\")\n",
    "    id_col = lower.get(\"id\")\n",
    "    # Все столбцы, которые подходят под шаблон pixel\\d+\n",
    "    pixel_cols = [c for c in df.columns if _PIXEL_RE.match(c)]\n",
    "    # Сортируем по номеру пикселя, чтобы получить правильный порядок 0…783\n",
    "    pixel_cols.sort(key=lambda x: int(_PIXEL_RE.match(x).group(1)))\n",
    "    # Обязательно должны быть все 784 пикселя (28 × 28)\n",
    "    if len(pixel_cols) != 784:\n",
    "        raise ValueError(f\"Expected 784 pixel cols, got {len(pixel_cols)}\")\n",
    "    return label_col, id_col, pixel_cols\n",
    "\n",
    "\n",
    "# 2. Очистка и приведение данных\n",
    "def _clean(df: pd.DataFrame, is_train: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Преобразует «сырае» CSV-данные к числовому виду без пропусков.\n",
    "\n",
    "    1. Преобразует все pixel-значения к float32, заменяя нечисловые на 0.\n",
    "    2. Ограничивает допустимый диапазон [0, 255].\n",
    "    3. Для тренировочных данных:\n",
    "       * удаляет строки без label,\n",
    "       * обрезает метки вне диапазона 0–9.\n",
    "    4. Сбрасывает индекс.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Исходные данные.\n",
    "    is_train : bool\n",
    "        True — это обучающая выборка с колонкой label.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Очищенный датафрейм, готовый к использованию в Dataset.\n",
    "    \"\"\"\n",
    "    label_col, _, pixel_cols = _detect_columns(df)\n",
    "    df[pixel_cols] = (\n",
    "        df[pixel_cols]\n",
    "        .apply(pd.to_numeric, errors=\"coerce\")\n",
    "        .fillna(0)\n",
    "        .clip(0, 255)\n",
    "        .astype(np.float32)\n",
    "    )\n",
    "    if is_train:\n",
    "        df = df.dropna(subset=[label_col])\n",
    "        df[label_col] = df[label_col].astype(int)\n",
    "        df = df[df[label_col].between(0, 9)]\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# 3. PyTorch-совместимый Dataset\n",
    "class FashionCSVDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset для Fashion-MNIST, который читает изображения прямо из CSV.\n",
    "\n",
    "    Параметры\n",
    "    ---------\n",
    "    df : pd.DataFrame\n",
    "        Предварительно очищенный датафрейм (см. `_clean`).\n",
    "    training : bool\n",
    "        True, если у строк есть метки (колонка label).\n",
    "    transform : Callable | None\n",
    "        Аугментации/препроцесс, совместимые с torchvison.transforms.\n",
    "        Ожидают tensor формата (C, H, W).\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame, *, training: bool, transform=None):\n",
    "        label_col, id_col, pixel_cols = _detect_columns(df)\n",
    "        self.transform = transform\n",
    "        # Ids: если столбца нет, генерируем индексы 0..N-1\n",
    "        self.ids = df[id_col].astype(int).to_numpy() if id_col else np.arange(len(df))\n",
    "        # Целевые метки (None в тесте)\n",
    "        self.targets = df[label_col].astype(int).to_numpy() if training else None\n",
    "        # Массив изображений в формате (N, 28, 28) и типе float32\n",
    "        self.images = (df[pixel_cols].to_numpy().reshape(-1, 28, 28) / 255.0).astype(np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \"\"\"\n",
    "        Возвращает тензор изображения и либо:\n",
    "        * метку (train)   — (x, y)\n",
    "        * id (inference)  — (x, id)\n",
    "        \"\"\"\n",
    "        x = torch.from_numpy(self.images[idx]).unsqueeze(0)  # (1,28,28)\n",
    "        # Аугментации\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        if self.targets is None:\n",
    "            return x, int(self.ids[idx])\n",
    "        return x, int(self.targets[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a0911e-6e23-4d1a-9b6d-8bfda465f4eb",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d841fd65-753f-40af-9cb2-faa903a64953",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1 — 32 ch\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), nn.Dropout2d(0.25),\n",
    "            # Block 2 — 64 ch\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), nn.Dropout2d(0.25),\n",
    "            # Block 3 — 128 ch\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2), nn.Dropout2d(0.25),\n",
    "            # Global pooling\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, 256), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "            nn.Linear(256, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Входной батч формы (B, 1, 28, 28)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Логиты размера (B, 10)\n",
    "        \"\"\"\n",
    "        x = self.features(x)     # извлекаем признаковое описание\n",
    "        x = self.classifier(x)   # предсказываем класс\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02de634d-0bd3-43c7-bc15-934dca81fbe8",
   "metadata": {},
   "source": [
    "# Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "555072fe-36fb-4164-95d6-2953482f7ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, scheduler, device):\n",
    "    \"\"\"\n",
    "    Один проход по всему обучающему набору.\n",
    "\n",
    "    * Переключаем сеть в train-режим (`model.train()`) — активируются Dropout и\n",
    "      BatchNorm собирает статистику.\n",
    "    * Для каждого mini-batch:\n",
    "        1. Переносим данные на GPU/CPU.\n",
    "        2. Обнуляем градиенты (`optimizer.zero_grad()`).\n",
    "        3. Считаем loss и back-prop (`loss.backward()`).\n",
    "        4. Обновляем веса (`optimizer.step()`).\n",
    "        5. Делаем шаг LR-плана (`scheduler.step()`);  \n",
    "    * Возвращаем средний loss за эпоху, чтобы мониторить кривую обучения.\n",
    "    \"\"\"\n",
    "    model.train(); epoch_loss = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(x), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        epoch_loss += loss.item() * y.size(0)\n",
    "    return epoch_loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    \"\"\"\n",
    "    Оценка точности (Accuracy) на валидационном лоадере.\n",
    "    \"\"\"\n",
    "    model.eval(); preds, targets = [], []\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        preds.append(model(x)); targets.append(y)\n",
    "    preds = torch.cat(preds); targets = torch.cat(targets)\n",
    "    return tm_accuracy(preds, targets, task='multiclass', num_classes=10).item()\n",
    "\n",
    "\n",
    "def fit(model, tr_loader, val_loader, device, *, epochs=30, patience=8, lr=3e-3):\n",
    "    \"\"\"\n",
    "    Полный цикл обучения + ранняя остановка (Early Stopping).\n",
    "\n",
    "    Параметры\n",
    "    ---------\n",
    "    model : nn.Module\n",
    "        Наша CNN / DenseNet.\n",
    "    tr_loader, val_loader : DataLoader\n",
    "        Лоадеры для train и validation.\n",
    "    device : torch.device\n",
    "        'cuda' или 'cpu'.\n",
    "    epochs : int\n",
    "        Максимальное число эпох.\n",
    "    patience : int\n",
    "        Сколько эпох подряд можно не улучшаться прежде чем остановиться.\n",
    "    lr : float\n",
    "        Пиковый learning rate для OneCycle.\n",
    "\n",
    "    Возвращает\n",
    "    ----------\n",
    "    nn.Module\n",
    "        Лучшая (по val-accuracy) версия модели, загруженная из чекпойнта.\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=lr, epochs=epochs, steps_per_epoch=len(tr_loader), pct_start=0.3)\n",
    "\n",
    "    best, n_bad, ckpt = 0.0, 0, Path('best_model.pt')\n",
    "    for ep in range(1, epochs + 1):\n",
    "        tr_loss = train_one_epoch(model, tr_loader, criterion, optimizer, scheduler, device)\n",
    "        val_acc = evaluate(model, val_loader, device)\n",
    "        if val_acc > best + 1e-4:\n",
    "            best, n_bad = val_acc, 0; torch.save(model.state_dict(), ckpt)\n",
    "        else:\n",
    "            n_bad += 1\n",
    "        print(f'Epoch {ep:02d}: loss={tr_loss:.4f}  val_acc={val_acc:.4f}  best={best:.4f}')\n",
    "        if n_bad >= patience:\n",
    "            print(f'Early stopping (patience={patience}) at epoch {ep}'); break\n",
    "\n",
    "    model.load_state_dict(torch.load(ckpt)); return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea3810c-1dc0-4564-a885-0c92fe6b237a",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04abcefe-d9ab-4d7b-b821-3f24ccd45d5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = _clean(pd.read_csv(\"fmnist_train.csv\"), is_train=True)\n",
    "test_df  = _clean(pd.read_csv(\"fmnist_test.csv\"),  is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5fc0087-fef0-454e-8eb2-11e080a51f34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert train_df.isna().sum().sum() == 0, \"NaN present in train\"  # quick sanity\n",
    "assert test_df.isna().sum().sum() == 0, \"NaN present in test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71b3b505-cf0f-465d-88bb-c7638525f6ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17040, 786)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "507b7c91-33ae-4403-b9d3-044e0ae50e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 785)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4865d0-4d32-4921-940c-24fb556a67fc",
   "metadata": {},
   "source": [
    "# Make dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42c8247d-7303-467b-ac00-6f9799511df7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "epochs = 150\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04d617db-9a7b-47ac-be7c-4bf75db50164",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_col = [c for c in train_df.columns if c.lower() == 'label'][0]\n",
    "tr_df, val_df = train_test_split(train_df, test_size=0.1, stratify=train_df[label_col], random_state=42)\n",
    "\n",
    "aug = transforms.Compose([\n",
    "    transforms.RandomCrop(28, padding=4),\n",
    "    transforms.RandomRotation(10, interpolation=InterpolationMode.BILINEAR),\n",
    "    transforms.RandomAffine(0, translate=(0.08, 0.08), scale=(0.95, 1.05)),\n",
    "    transforms.RandomHorizontalFlip(0.4),\n",
    "    transforms.RandomErasing(p=0.10, scale=(0.02, 0.12)),\n",
    "])\n",
    "\n",
    "\n",
    "train_ds = FashionCSVDataset(tr_df, training=True, transform=aug)\n",
    "val_ds   = FashionCSVDataset(val_df, training=True, transform=None)\n",
    "\n",
    "dl_kwargs = dict(batch_size=batch_size, num_workers=2, pin_memory=True)\n",
    "train_loader = DataLoader(train_ds, shuffle=True, **dl_kwargs)\n",
    "val_loader   = DataLoader(val_ds, shuffle=False, **dl_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48af62c4-e410-4197-be37-048f3f23528f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: loss=2.1946  val_acc=0.3944  best=0.3944\n",
      "Epoch 02: loss=1.8224  val_acc=0.6056  best=0.6056\n",
      "Epoch 03: loss=1.5348  val_acc=0.6696  best=0.6696\n",
      "Epoch 04: loss=1.3436  val_acc=0.7101  best=0.7101\n",
      "Epoch 05: loss=1.1929  val_acc=0.7383  best=0.7383\n",
      "Epoch 06: loss=1.1029  val_acc=0.7653  best=0.7653\n",
      "Epoch 07: loss=1.0193  val_acc=0.7612  best=0.7653\n",
      "Epoch 08: loss=0.9827  val_acc=0.7817  best=0.7817\n",
      "Epoch 09: loss=0.9426  val_acc=0.8052  best=0.8052\n",
      "Epoch 10: loss=0.9174  val_acc=0.7876  best=0.8052\n",
      "Epoch 11: loss=0.8812  val_acc=0.7934  best=0.8052\n",
      "Epoch 12: loss=0.8697  val_acc=0.8116  best=0.8116\n",
      "Epoch 13: loss=0.8534  val_acc=0.8263  best=0.8263\n",
      "Epoch 14: loss=0.8302  val_acc=0.8128  best=0.8263\n",
      "Epoch 15: loss=0.8196  val_acc=0.8322  best=0.8322\n",
      "Epoch 16: loss=0.8034  val_acc=0.8228  best=0.8322\n",
      "Epoch 17: loss=0.7990  val_acc=0.8410  best=0.8410\n",
      "Epoch 18: loss=0.7865  val_acc=0.8545  best=0.8545\n",
      "Epoch 19: loss=0.7679  val_acc=0.8369  best=0.8545\n",
      "Epoch 20: loss=0.7589  val_acc=0.8562  best=0.8562\n",
      "Epoch 21: loss=0.7604  val_acc=0.8709  best=0.8709\n",
      "Epoch 22: loss=0.7352  val_acc=0.8621  best=0.8709\n",
      "Epoch 23: loss=0.7317  val_acc=0.8562  best=0.8709\n",
      "Epoch 24: loss=0.7271  val_acc=0.8574  best=0.8709\n",
      "Epoch 25: loss=0.7163  val_acc=0.8750  best=0.8750\n",
      "Epoch 26: loss=0.7076  val_acc=0.8762  best=0.8762\n",
      "Epoch 27: loss=0.7008  val_acc=0.8803  best=0.8803\n",
      "Epoch 28: loss=0.6955  val_acc=0.8873  best=0.8873\n",
      "Epoch 29: loss=0.6951  val_acc=0.8862  best=0.8873\n",
      "Epoch 30: loss=0.6853  val_acc=0.8826  best=0.8873\n",
      "Epoch 31: loss=0.6751  val_acc=0.8856  best=0.8873\n",
      "Epoch 32: loss=0.6711  val_acc=0.8762  best=0.8873\n",
      "Epoch 33: loss=0.6679  val_acc=0.8967  best=0.8967\n",
      "Epoch 34: loss=0.6631  val_acc=0.8926  best=0.8967\n",
      "Epoch 35: loss=0.6530  val_acc=0.8908  best=0.8967\n",
      "Epoch 36: loss=0.6494  val_acc=0.8973  best=0.8973\n",
      "Epoch 37: loss=0.6494  val_acc=0.8862  best=0.8973\n",
      "Epoch 38: loss=0.6485  val_acc=0.8920  best=0.8973\n",
      "Epoch 39: loss=0.6441  val_acc=0.8979  best=0.8979\n",
      "Epoch 40: loss=0.6335  val_acc=0.8932  best=0.8979\n",
      "Epoch 41: loss=0.6348  val_acc=0.8856  best=0.8979\n",
      "Epoch 42: loss=0.6299  val_acc=0.8973  best=0.8979\n",
      "Epoch 43: loss=0.6302  val_acc=0.8820  best=0.8979\n",
      "Epoch 44: loss=0.6118  val_acc=0.9020  best=0.9020\n",
      "Epoch 45: loss=0.6199  val_acc=0.8932  best=0.9020\n",
      "Epoch 46: loss=0.6214  val_acc=0.8920  best=0.9020\n",
      "Epoch 47: loss=0.6179  val_acc=0.9038  best=0.9038\n",
      "Epoch 48: loss=0.6074  val_acc=0.9067  best=0.9067\n",
      "Epoch 49: loss=0.6067  val_acc=0.9008  best=0.9067\n",
      "Epoch 50: loss=0.6073  val_acc=0.8985  best=0.9067\n",
      "Epoch 51: loss=0.6079  val_acc=0.8862  best=0.9067\n",
      "Epoch 52: loss=0.6060  val_acc=0.9108  best=0.9108\n",
      "Epoch 53: loss=0.6026  val_acc=0.9126  best=0.9126\n",
      "Epoch 54: loss=0.5982  val_acc=0.9096  best=0.9126\n",
      "Epoch 55: loss=0.5960  val_acc=0.9108  best=0.9126\n",
      "Epoch 56: loss=0.5962  val_acc=0.9038  best=0.9126\n",
      "Epoch 57: loss=0.5940  val_acc=0.9002  best=0.9126\n",
      "Epoch 58: loss=0.5881  val_acc=0.9184  best=0.9184\n",
      "Epoch 59: loss=0.5907  val_acc=0.9055  best=0.9184\n",
      "Epoch 60: loss=0.5867  val_acc=0.9114  best=0.9184\n",
      "Epoch 61: loss=0.5863  val_acc=0.9090  best=0.9184\n",
      "Epoch 62: loss=0.5881  val_acc=0.9131  best=0.9184\n",
      "Epoch 63: loss=0.5823  val_acc=0.8985  best=0.9184\n",
      "Epoch 64: loss=0.5764  val_acc=0.9126  best=0.9184\n",
      "Epoch 65: loss=0.5779  val_acc=0.9167  best=0.9184\n",
      "Epoch 66: loss=0.5799  val_acc=0.9043  best=0.9184\n",
      "Epoch 67: loss=0.5772  val_acc=0.9196  best=0.9196\n",
      "Epoch 68: loss=0.5756  val_acc=0.9114  best=0.9196\n",
      "Epoch 69: loss=0.5715  val_acc=0.9102  best=0.9196\n",
      "Epoch 70: loss=0.5720  val_acc=0.9208  best=0.9208\n",
      "Epoch 71: loss=0.5727  val_acc=0.9102  best=0.9208\n",
      "Epoch 72: loss=0.5739  val_acc=0.9126  best=0.9208\n",
      "Epoch 73: loss=0.5690  val_acc=0.9114  best=0.9208\n",
      "Epoch 74: loss=0.5642  val_acc=0.9243  best=0.9243\n",
      "Epoch 75: loss=0.5607  val_acc=0.9249  best=0.9249\n",
      "Epoch 76: loss=0.5667  val_acc=0.9190  best=0.9249\n",
      "Epoch 77: loss=0.5616  val_acc=0.9219  best=0.9249\n",
      "Epoch 78: loss=0.5652  val_acc=0.9266  best=0.9266\n",
      "Epoch 79: loss=0.5566  val_acc=0.9161  best=0.9266\n",
      "Epoch 80: loss=0.5590  val_acc=0.9173  best=0.9266\n",
      "Epoch 81: loss=0.5581  val_acc=0.9231  best=0.9266\n",
      "Epoch 82: loss=0.5571  val_acc=0.9126  best=0.9266\n",
      "Epoch 83: loss=0.5517  val_acc=0.9237  best=0.9266\n",
      "Epoch 84: loss=0.5570  val_acc=0.9184  best=0.9266\n",
      "Epoch 85: loss=0.5445  val_acc=0.9219  best=0.9266\n",
      "Epoch 86: loss=0.5529  val_acc=0.9278  best=0.9278\n",
      "Epoch 87: loss=0.5482  val_acc=0.9167  best=0.9278\n",
      "Epoch 88: loss=0.5502  val_acc=0.9208  best=0.9278\n",
      "Epoch 89: loss=0.5447  val_acc=0.9325  best=0.9325\n",
      "Epoch 90: loss=0.5443  val_acc=0.9196  best=0.9325\n",
      "Epoch 91: loss=0.5470  val_acc=0.9343  best=0.9343\n",
      "Epoch 92: loss=0.5355  val_acc=0.9190  best=0.9343\n",
      "Epoch 93: loss=0.5429  val_acc=0.9302  best=0.9343\n",
      "Epoch 94: loss=0.5398  val_acc=0.9237  best=0.9343\n",
      "Epoch 95: loss=0.5402  val_acc=0.9278  best=0.9343\n",
      "Epoch 96: loss=0.5352  val_acc=0.9161  best=0.9343\n",
      "Epoch 97: loss=0.5359  val_acc=0.9296  best=0.9343\n",
      "Epoch 98: loss=0.5298  val_acc=0.9278  best=0.9343\n",
      "Epoch 99: loss=0.5313  val_acc=0.9208  best=0.9343\n",
      "Epoch 100: loss=0.5304  val_acc=0.9272  best=0.9343\n",
      "Epoch 101: loss=0.5271  val_acc=0.9325  best=0.9343\n",
      "Early stopping (patience=10) at epoch 101\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CNN().to(device)\n",
    "model = fit(model, train_loader, val_loader, device, epochs=epochs, patience=patience)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b013151f-b75c-4066-8e4c-98d31a631eb2",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cfc4442-259f-4544-8f1c-1481068271db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved sample_submission.csv (rows=10000)\n"
     ]
    }
   ],
   "source": [
    "test_ds = FashionCSVDataset(test_df, training=False, transform=None)\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=2,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "all_ids: list[int] = []\n",
    "all_preds: list[int] = []\n",
    "with torch.no_grad():\n",
    "    for x, ids in test_loader:\n",
    "        logits = model(x.to(device))\n",
    "        all_preds.extend(logits.argmax(1).cpu().tolist())\n",
    "        all_ids.extend(ids.tolist())\n",
    "\n",
    "submission = pd.DataFrame({\"id\": all_ids, \"label\": all_preds})\n",
    "submission.to_csv(\"sample_submission.csv\", index=False)\n",
    "print(f\"Saved sample_submission.csv (rows={len(submission)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ba321e-1eb1-432d-aee2-cc22e65a4675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ad276d-5349-4e8a-82a8-91c77f7eabb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
