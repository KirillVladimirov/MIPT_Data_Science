{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3190a33c-1f92-4b6f-8c05-e8a8e67091dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q albumentations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87428dc8-e704-4206-868e-cd01f8544d6f",
   "metadata": {},
   "source": [
    "# 1. Общие параметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e65c82e-2706-41f4-b9f5-948625b157c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/skitarii/PycharmProjects/mipt-masters/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 20\n",
    "LR = 3e-4\n",
    "IMG_SIZE = 48       \n",
    "NUM_CLASSES = 26           # A–Z\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ffcd8e-408c-49e8-b479-752b96457a2f",
   "metadata": {},
   "source": [
    "# 2. Загрузка и валидационный сплит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f192184-49a6-4f4a-a7ae-5f7a54b52654",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = np.load('./mipt-dl-captcha-2025/mds-misis-dl-captchan/images.npy')      # (20000, 48, 48, 3)\n",
    "labels = np.load('./mipt-dl-captcha-2025/mds-misis-dl-captchan/labels.npy')      # (20000,)\n",
    "\n",
    "# Разделим 10 % под валидацию\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.10, random_state=SEED)\n",
    "train_idx, val_idx = next(sss.split(images, labels))\n",
    "\n",
    "train_imgs, val_imgs = images[train_idx], images[val_idx]\n",
    "train_lbls, val_lbls = labels[train_idx], labels[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb5401a-d2eb-454c-af3d-f2ee4b6fc23a",
   "metadata": {},
   "source": [
    "# 3. Аугментации и Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c89e5a87-b7c8-4f09-9833-24f267c16e6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_tfms = A.Compose([\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.Perspective(scale=(0.05,0.15), p=0.5),\n",
    "    A.MotionBlur(p=0.2),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_tfms = A.Compose([\n",
    "    A.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5)),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5dc98a-6317-4649-828a-eb9a6b5042f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CaptchaDataset(Dataset):\n",
    "    def __init__(self, imgs, lbls=None, tfms=None):\n",
    "        self.imgs  = imgs\n",
    "        self.lbls  = lbls\n",
    "        self.tfms  = tfms            # сохраняем аугментации\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.imgs[idx]\n",
    "\n",
    "        # --- корректное применение трансформаций ---\n",
    "        if self.tfms is not None:\n",
    "            img = self.tfms(image=img)[\"image\"]          # Albumentations → Tensor\n",
    "        else:\n",
    "            img = torch.from_numpy(img).permute(2, 0, 1).float() / 255.\n",
    "\n",
    "        if self.lbls is not None:\n",
    "            label = torch.tensor(self.lbls[idx], dtype=torch.long)\n",
    "            return img, label\n",
    "\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2dc7df-3522-4109-848b-6fd769376bd8",
   "metadata": {},
   "source": [
    "# 4. DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "228c123c-45ba-4c9d-a523-46882c4dd41c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds = CaptchaDataset(train_imgs, train_lbls, train_tfms)\n",
    "val_ds   = CaptchaDataset(val_imgs,   val_lbls,   val_tfms)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4, pin_memory=True)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f89e36-af3b-47a8-b97a-20c7d7da7ef6",
   "metadata": {},
   "source": [
    "# 5. Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd52c1d9-1cbf-4875-baa0-7bbf8d2b5bc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)  # адаптация под 48×48\n",
    "model.maxpool = nn.Identity()\n",
    "model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77fe5a2-64b4-480a-87c5-1c24b61d5fdb",
   "metadata": {},
   "source": [
    "# 6. Оптимизатор, scheduler, метрика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a74e8fb-4477-4351-a589-89e9374d2589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "metric = MulticlassAccuracy(num_classes=NUM_CLASSES, average='micro').to(DEVICE)\n",
    "scaler = GradScaler(enabled=(DEVICE==\"cuda\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428cf0d7-01b5-4e27-8cc9-0a11f5fc12b1",
   "metadata": {},
   "source": [
    "# 7. Цикл обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b356775-941e-4dd6-98b3-eb9c314041ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 Val loss: 0.7565 | Val accuracy: 87.9000%\n",
      "Epoch 2/20 Val loss: 0.5825 | Val accuracy: 93.9500%\n",
      "Epoch 3/20 Val loss: 0.5354 | Val accuracy: 95.2000%\n",
      "Epoch 4/20 Val loss: 0.5166 | Val accuracy: 95.5000%\n",
      "Epoch 5/20 Val loss: 0.5757 | Val accuracy: 93.5500%\n",
      "Epoch 6/20 Val loss: 0.5086 | Val accuracy: 95.3500%\n",
      "Epoch 7/20 Val loss: 0.4903 | Val accuracy: 96.2500%\n",
      "Epoch 8/20 Val loss: 0.4851 | Val accuracy: 96.4000%\n",
      "Epoch 9/20 Val loss: 0.4774 | Val accuracy: 96.3500%\n",
      "Epoch 10/20 Val loss: 0.4614 | Val accuracy: 97.3000%\n",
      "Epoch 11/20 Val loss: 0.4552 | Val accuracy: 97.1000%\n",
      "Epoch 12/20 Val loss: 0.4500 | Val accuracy: 97.0000%\n",
      "Epoch 13/20 Val loss: 0.4417 | Val accuracy: 97.4500%\n",
      "Epoch 14/20 Val loss: 0.4416 | Val accuracy: 97.7000%\n",
      "Epoch 15/20 Val loss: 0.5105 | Val accuracy: 95.2500%\n",
      "Epoch 16/20 Val loss: 0.4936 | Val accuracy: 95.8500%\n",
      "Epoch 17/20 Val loss: 0.4737 | Val accuracy: 96.6000%\n",
      "Epoch 18/20 Val loss: 0.4798 | Val accuracy: 96.3000%\n",
      "Epoch 19/20 Val loss: 0.4640 | Val accuracy: 96.5500%\n",
      "Epoch 20/20 Val loss: 0.4547 | Val accuracy: 96.6000%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    for imgs, lbls in train_dl:\n",
    "        imgs, lbls = imgs.to(DEVICE), lbls.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast(enabled=(DEVICE==\"cuda\")):\n",
    "            logits = model(imgs)\n",
    "            loss   = criterion(logits, lbls)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step(epoch + (len(train_dl) / len(train_dl)))\n",
    "    \n",
    "    # валидация\n",
    "    model.eval(); metric.reset()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad(), autocast(enabled=(DEVICE==\"cuda\")):\n",
    "        for imgs, lbls in val_dl:\n",
    "            imgs, lbls = imgs.to(DEVICE), lbls.to(DEVICE)\n",
    "            logits = model(imgs)\n",
    "            val_loss += criterion(logits, lbls).item() * imgs.size(0)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            metric.update(preds, lbls)\n",
    "    val_acc = metric.compute().item()\n",
    "    print(f'Epoch {epoch+1}/{EPOCHS} '\n",
    "          f'Val loss: {val_loss/len(val_ds):.4f} | Val accuracy: {val_acc:.4%}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c900ed-08a4-4576-b193-46864e39c147",
   "metadata": {},
   "source": [
    "# 8. Инференс на тесте и сабмит"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c885e78b-31c1-40d1-b327-8ec8ae6f22ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission.csv готов!\n"
     ]
    }
   ],
   "source": [
    "test_imgs = np.load('./mipt-dl-captcha-2025/mds-misis-dl-captchan/images_sub.npy')\n",
    "test_ds   = CaptchaDataset(test_imgs, tfms=val_tfms)\n",
    "test_dl   = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "with torch.no_grad(), autocast(enabled=(DEVICE==\"cuda\")):\n",
    "    for imgs in test_dl:\n",
    "        imgs = imgs.to(DEVICE)\n",
    "        logits = model(imgs)\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "all_preds = np.concatenate(all_preds)\n",
    "\n",
    "# создаём файл сабмита\n",
    "sub = pd.read_csv('./mipt-dl-captcha-2025/mds-misis-dl-captchan/sample_submission.csv')\n",
    "sub['Category'] = all_preds\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "print('submission.csv готов!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff085816-ade5-48bc-9866-e59b29d582f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f9c44e-f2d5-4f13-8d69-774bd80e16cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b961479f-0ad9-4916-8e85-63731fd8a945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ad12e-b739-47bd-b251-94abf29e7fef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
